# Guide d'Utilisation Avanc√© - Marker PDF

Ce guide vous accompagne dans l'utilisation compl√®te du projet Marker pour comprendre et convertir des PDFs en markdown de mani√®re optimale.

## üéØ Objectifs et Cas d'Usage

Marker excelle dans plusieurs domaines :

- **üìö Documents Acad√©miques** : Articles, th√®ses, rapports de recherche avec √©quations complexes
- **üìä Rapports Financiers** : √âtats financiers, bilans avec tableaux d√©taill√©s
- **üìã Documents Administratifs** : Formulaires, contrats, documentation officielle
- **üè≠ Manuels Techniques** : Documentation produit, guides d'installation
- **üì∞ Articles et Publications** : Journaux, magazines, newsletters

## üöÄ D√©marrage Rapide

### 1. Configuration Initiale

```bash
# 1. Configurez votre environnement
cd custom_docs/
python scripts/setup_environment.py

# 2. Placez vos PDFs dans le dossier inputs/
cp votre_document.pdf inputs/

# 3. Configurez vos cl√©s API (optionnel mais recommand√©)
export GOOGLE_API_KEY="your_gemini_key_here"
# ou
export CLAUDE_API_KEY="your_claude_key_here"
# ou  
export OPENAI_API_KEY="your_openai_key_here"
```

### 2. Premi√®re Conversion

```bash
# Analyse pr√©liminaire (recommand√©e)
python scripts/analyze_pdf_deep.py inputs/document.pdf --output outputs/

# Conversion selon les recommandations de l'analyse
python scripts/convert_to_markdown.py inputs/document.pdf --mode balanced --output outputs/
```

## üîç Workflow Complet d'Analyse et Conversion

### √âtape 1 : Analyse Approfondie

L'analyse pr√©liminaire vous aide √† comprendre votre document et choisir la strat√©gie optimale :

```bash
# Analyse compl√®te avec sauvegarde
python scripts/analyze_pdf_deep.py inputs/rapport_annuel.pdf \
  --output outputs/analyses/ \
  --debug

# Analyse avec LLM pour documents complexes
python scripts/analyze_pdf_deep.py inputs/article_scientifique.pdf \
  --llm \
  --output outputs/analyses/
```

**Interpr√©tation des r√©sultats :**

```json
{
  "structure_analysis": {
    "reading_complexity": "complex",        // Niveau de complexit√©
    "total_pages": 45,
    "content_distribution": {
      "Text": 120,                         // Blocs de texte standard
      "Table": 15,                         // Tableaux d√©tect√©s
      "Equation": 8,                       // √âquations math√©matiques
      "Figure": 12                         // Images et graphiques
    }
  },
  "quality_analysis": {
    "confidence_score": 0.75,              // Score de confiance (0-1)
    "text_extraction_methods": {
      "pdftext": 35,                       // Pages avec texte extractible
      "ocr": 10                           // Pages n√©cessitant l'OCR
    }
  },
  "recommendations": [
    "Utiliser --use_llm pour une meilleure pr√©cision",
    "Document riche en tableaux - consid√©rer TableConverter"
  ]
}
```

### √âtape 2 : Choix de la Strat√©gie de Conversion

Bas√© sur l'analyse, choisissez votre approche :

#### Documents Simples (complexity: "simple" ou "moderate")
```bash
# Mode rapide pour tests et prototypage
python scripts/convert_to_markdown.py inputs/document.pdf \
  --mode fast \
  --output outputs/

# Mode √©quilibr√© pour usage quotidien  
python scripts/convert_to_markdown.py inputs/document.pdf \
  --mode balanced \
  --output outputs/
```

#### Documents Complexes (complexity: "complex" ou "very_complex")
```bash
# Mode qualit√© maximale avec LLM
python scripts/convert_to_markdown.py inputs/document.pdf \
  --mode quality \
  --output outputs/

# Conversion avec OCR forc√© pour textes de mauvaise qualit√©
python scripts/convert_to_markdown.py inputs/document_scann√©.pdf \
  --mode quality \
  --output outputs/
```

### √âtape 3 : Extraction Sp√©cialis√©e (Optionnel)

Pour des besoins sp√©cifiques, extrayez des √©l√©ments particuliers :

#### Extraction de Tables
```bash
# Tables simples
python scripts/extract_specific_content.py inputs/rapport.pdf \
  --content-type tables \
  --output outputs/tables/

# Tables complexes avec LLM
python scripts/extract_specific_content.py inputs/rapport_financier.pdf \
  --content-type tables \
  --llm \
  --output outputs/tables/
```

#### Extraction d'√âquations Math√©matiques
```bash
# Articles scientifiques avec √©quations
python scripts/extract_specific_content.py inputs/paper.pdf \
  --content-type equations \
  --llm \
  --output outputs/equations/
```

#### Extraction d'Images et Figures
```bash
# Extraction compl√®te avec m√©tadonn√©es
python scripts/extract_specific_content.py inputs/manual.pdf \
  --content-type images \
  --output outputs/images/
```

#### Recherche par Sections/Mots-cl√©s
```bash
# Extraction de sections sp√©cifiques
python scripts/extract_specific_content.py inputs/these.pdf \
  --content-type sections \
  --keywords "introduction,methodology,results,conclusion,discussion" \
  --output outputs/sections/
```

## üìä Traitement en Lot (Batch Processing)

Pour traiter de nombreux documents efficacement :

### Traitement Parall√®le Standard
```bash
# Traitement avec d√©tection automatique des workers
python scripts/batch_processor.py inputs/ outputs/ \
  --strategy parallel \
  --format markdown

# Contr√¥le fin du parall√©lisme
python scripts/batch_processor.py inputs/ outputs/ \
  --strategy parallel \
  --workers 4 \
  --llm
```

### Traitement Haute Performance
```bash
# Environnement multi-GPU
python scripts/batch_processor.py inputs/ outputs/ \
  --strategy multi_gpu \
  --llm \
  --format json

# Traitement conservateur pour gros documents
python scripts/batch_processor.py inputs/ outputs/ \
  --strategy sequential \
  --llm \
  --force-ocr
```

### Monitoring et Logs
```bash
# Surveillance en temps r√©el
tail -f batch_processing.log

# V√©rification des ressources syst√®me
watch -n 2 'ps aux | grep python | grep marker'
```

## üéõÔ∏è Optimisation des Performances

### Configuration Hardware

| Configuration | Recommandation | Workers | Mode |
|---------------|----------------|---------|------|
| **Basique** (CPU 4-core, 8GB RAM) | Documents simples | 2-3 | fast/balanced |
| **Standard** (CPU 8-core, 16GB RAM) | Usage quotidien | 4-6 | balanced/quality |
| **Avanc√©e** (CPU 16-core, 32GB RAM, GPU) | Traitement intensif | 8-12 | quality |
| **Serveur** (CPU 32-core, 64GB RAM, GPU Pro) | Production | 16+ | quality |

### Variables d'Environnement Optimales

```bash
# Configuration GPU (si disponible)
export TORCH_DEVICE=cuda

# Optimisation m√©moire
export TOKENIZERS_PARALLELISM=false

# R√©pertoires de travail
export OUTPUT_DIR=/path/to/your/outputs

# APIs pour mode LLM
export GOOGLE_API_KEY=your_key_here
```

### Monitoring des Ressources

```bash
# Installation d'outils de monitoring
pip install psutil gpustat

# Script de surveillance
python -c "
import psutil
import time
while True:
    cpu = psutil.cpu_percent(interval=1)
    mem = psutil.virtual_memory()
    print(f'CPU: {cpu}% | RAM: {mem.percent}% ({mem.used//1024**3}GB/{mem.total//1024**3}GB)')
    time.sleep(5)
"
```

## üìà Exemples Concrets par Secteur

### üè• Secteur M√©dical
```bash
# Rapports m√©dicaux avec terminologie complexe
python scripts/convert_to_markdown.py inputs/rapport_medical.pdf \
  --mode quality \
  --output outputs/medical/

# Extraction de tableaux de donn√©es cliniques
python scripts/extract_specific_content.py inputs/etude_clinique.pdf \
  --content-type tables \
  --llm \
  --output outputs/medical/tables/
```

### üíº Finance et Comptabilit√©
```bash
# √âtats financiers avec nombreux tableaux
python scripts/extract_specific_content.py inputs/bilan.pdf \
  --content-type tables \
  --llm \
  --output outputs/finance/

# Conversion compl√®te de rapports annuels
python scripts/convert_to_markdown.py inputs/rapport_annuel.pdf \
  --mode quality \
  --output outputs/finance/
```

### üî¨ Recherche Scientifique
```bash
# Article avec √©quations et figures
python scripts/analyze_pdf_deep.py inputs/nature_paper.pdf --llm
python scripts/convert_to_markdown.py inputs/nature_paper.pdf --mode quality
python scripts/extract_specific_content.py inputs/nature_paper.pdf \
  --content-type equations --llm
```

### üèõÔ∏è Juridique
```bash
# Documents contractuels
python scripts/convert_to_markdown.py inputs/contrat.pdf \
  --mode quality \
  --output outputs/legal/

# Extraction de clauses sp√©cifiques
python scripts/extract_specific_content.py inputs/contrat.pdf \
  --content-type sections \
  --keywords "obligations,responsabilit√©,r√©siliation,p√©nalit√©s"
```

## üîß D√©pannage Avanc√©

### Probl√®mes de M√©moire
```bash
# R√©duction des workers
python scripts/batch_processor.py inputs/ outputs/ --workers 1

# Mode s√©quentiel conservateur
python scripts/batch_processor.py inputs/ outputs/ --strategy sequential

# Monitoring m√©moire en temps r√©el
python -c "
import psutil
import time
process = psutil.Process()
while True:
    mem_info = process.memory_info()
    print(f'RSS: {mem_info.rss//1024**2}MB | VMS: {mem_info.vms//1024**2}MB')
    time.sleep(10)
" &
```

### Probl√®mes GPU
```bash
# V√©rification CUDA
nvidia-smi

# Force CPU si probl√®me GPU
export TORCH_DEVICE=cpu
python scripts/convert_to_markdown.py inputs/document.pdf

# Nettoyage cache GPU
python -c "import torch; torch.cuda.empty_cache()"
```

### Probl√®mes API LLM
```bash
# Test de connectivit√©
python scripts/setup_environment.py --check-only

# V√©rification des limites de rate
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models

# Mode sans LLM en cas de probl√®me
python scripts/convert_to_markdown.py inputs/document.pdf --mode balanced
```

### Debug Avanc√©
```bash
# Mode debug complet
python scripts/analyze_pdf_deep.py inputs/document.pdf \
  --debug \
  --output outputs/debug/

# Inspection des logs d√©taill√©s
tail -n 100 batch_processing.log | grep ERROR

# Analyse des performances
python -m cProfile -o profile_output.prof \
  scripts/convert_to_markdown.py inputs/document.pdf

# Visualisation du profile
pip install snakeviz
snakeviz profile_output.prof
```

## üìä M√©triques et √âvaluation de Qualit√©

### √âvaluation Automatique
```bash
# Comparaison avant/apr√®s traitement
python scripts/analyze_pdf_deep.py inputs/original.pdf --output outputs/analysis/
python scripts/convert_to_markdown.py inputs/original.pdf --mode quality --output outputs/
python scripts/analyze_pdf_deep.py outputs/original.md --output outputs/analysis/converted/
```

### M√©triques de Performance
```bash
# Temps de traitement par page
grep "processing_time\|pages_processed" outputs/*/report.json

# Taux de r√©ussite des conversions  
jq '.success_rate' outputs/batch_report_*.json

# Analyse de la distribution des types de contenu
jq '.structure_analysis.content_distribution' outputs/*_analysis.json
```

### Validation Qualitative
```bash
# G√©n√©ration d'un aper√ßu HTML pour v√©rification
python -c "
import markdown
with open('outputs/document.md', 'r') as f:
    content = f.read()
html = markdown.markdown(content, extensions=['tables', 'fenced_code'])
with open('outputs/document.html', 'w') as f:
    f.write(html)
print('Aper√ßu HTML g√©n√©r√© : outputs/document.html')
"
```

## üîÑ Workflows Automatis√©s

### Script de Traitement Complet
```bash
#!/bin/bash
# workflow_complet.sh

INPUT_DIR="inputs"
OUTPUT_DIR="outputs" 
ANALYSIS_DIR="$OUTPUT_DIR/analyses"

echo "üîç Phase 1: Analyse des documents"
mkdir -p "$ANALYSIS_DIR"
for pdf in "$INPUT_DIR"/*.pdf; do
    echo "Analyse de $(basename "$pdf")"
    python scripts/analyze_pdf_deep.py "$pdf" \
        --output "$ANALYSIS_DIR" \
        --llm
done

echo "üìÑ Phase 2: Conversion optimis√©e"
python scripts/batch_processor.py "$INPUT_DIR" "$OUTPUT_DIR" \
    --strategy parallel \
    --llm \
    --format markdown

echo "üìä Phase 3: G√©n√©ration du rapport final"
python -c "
import json
import glob
from pathlib import Path

analyses = []
for analysis_file in glob.glob('$ANALYSIS_DIR/*_analysis.json'):
    with open(analysis_file) as f:
        analyses.append(json.load(f))

print(f'üìä R√©sum√©: {len(analyses)} documents analys√©s')
complexities = [a.get('structure_analysis', {}).get('reading_complexity') for a in analyses]
print(f'Complexit√©s: {dict(zip(*zip(*[[c, complexities.count(c)] for c in set(complexities)])))}')
"

echo "‚úÖ Workflow termin√©!"
```

### Automatisation avec Cron
```bash
# Traitement automatique quotidien
# Ajouter dans crontab: crontab -e
# 0 2 * * * cd /path/to/marker/custom_docs && ./workflow_complet.sh >> logs/daily_processing.log 2>&1
```

Ce guide vous donne maintenant tous les outils pour ma√Ætriser Marker et traiter efficacement vos documents PDF selon vos besoins sp√©cifiques.

---

**üí° Conseils Pro :**
- Commencez toujours par une analyse pr√©liminaire
- Utilisez le mode LLM pour les documents importants
- Surveillez vos ressources syst√®me lors du traitement en lot
- Gardez des copies de vos configurations optimales
- N'h√©sitez pas √† combiner plusieurs approches selon le contexte