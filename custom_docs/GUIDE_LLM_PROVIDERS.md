# Guide des Providers LLM pour Marker

Ce guide explique comment utiliser les diff√©rents providers LLM avec les scripts custom_docs de Marker.

## üîß Configuration automatique

Tous les scripts utilisent maintenant le fichier `custom_docs/.env` pour charger automatiquement les cl√©s API. **Plus besoin d'exporter manuellement les variables d'environnement !**

### 1. Configurez votre fichier .env

Le fichier `custom_docs/.env` contient vos cl√©s API :

```bash
# Google Gemini API (recommand√©)
GOOGLE_API_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXX

# Claude API (Anthropic) 
CLAUDE_API_KEY=sk-ant-api03-XXXXXXXXXXXXXXXXXXXXXXX

# OpenAI API
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# Azure OpenAI (optionnel)
AZURE_API_KEY=your_azure_api_key
AZURE_ENDPOINT=your_azure_endpoint

# Configuration Marker
TORCH_DEVICE=cuda  # auto, cuda, ou cpu
OUTPUT_DIR=./outputs
```

### 2. Providers disponibles

| Provider | Statut | Installation requise | Qualit√© | Vitesse |
|----------|--------|---------------------|---------|---------|
| **gemini** | ‚úÖ Recommand√© | ‚úÖ Pr√©-install√© | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **bedrock** | ‚úÖ Claude 3.5 | `pip install boto3` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **claude** | ‚ö†Ô∏è Package requis | `pip install anthropic` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **openai** | ‚ö†Ô∏è Package requis | `pip install openai` | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **azure** | ‚ö†Ô∏è Package requis | `pip install openai` | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **ollama** | üîß Installation locale | Installation Ollama | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |

## üìã Utilisation des scripts

### analyze_pdf_deep.py

Analyse approfondie de PDF avec support multi-LLM :

```bash
# Utilisation automatique du meilleur provider disponible
python custom_docs/scripts/analyze_pdf_deep.py document.pdf --llm --output outputs/

# Forcer un provider sp√©cifique
python custom_docs/scripts/analyze_pdf_deep.py document.pdf --llm --provider gemini --output outputs/
python custom_docs/scripts/analyze_pdf_deep.py document.pdf --llm --provider claude --output outputs/
```

**Options :**
- `--llm` : Activer le mode LLM
- `--provider` : Choix du provider (`auto`, `gemini`, `claude`, `openai`, `azure`, `ollama`)
- `--debug` : Mode debug d√©taill√©

### convert_to_markdown.py

Conversion PDF vers Markdown avec LLM :

```bash
# Mode qualit√© avec LLM automatique
python custom_docs/scripts/convert_to_markdown.py document.pdf --mode quality --output outputs/

# Mode qualit√© avec provider sp√©cifique
python custom_docs/scripts/convert_to_markdown.py document.pdf --mode quality --provider gemini --output outputs/
```

**Modes :**
- `fast` : Conversion rapide sans LLM
- `balanced` : √âquilibr√© sans LLM
- `quality` : Qualit√© maximale avec LLM

### extract_specific_content.py

Extraction de contenu sp√©cifique avec LLM :

```bash
# Extraction de tableaux avec LLM
python custom_docs/scripts/extract_specific_content.py document.pdf --content-type tables --llm --provider gemini --output outputs/

# Extraction d'√©quations avec Claude
python custom_docs/scripts/extract_specific_content.py document.pdf --content-type equations --llm --provider claude --output outputs/
```

## üéØ Recommandations par cas d'usage

### Documents simples (texte principalement)
```bash
# Mode rapide sans LLM suffit
python custom_docs/scripts/convert_to_markdown.py document.pdf --mode fast
```

### Documents avec tableaux complexes
```bash
# Utiliser Gemini pour les tableaux
python custom_docs/scripts/extract_specific_content.py document.pdf --content-type tables --llm --provider gemini
```

### Documents scientifiques avec √©quations
```bash
# Claude excelle sur les √©quations math√©matiques
python custom_docs/scripts/analyze_pdf_deep.py document.pdf --llm --provider claude
```

### Documents multilingues
```bash
# Gemini g√®re bien le multilingue
python custom_docs/scripts/convert_to_markdown.py document.pdf --mode quality --provider gemini
```

## üõ†Ô∏è R√©solution de probl√®mes

### Erreur : "Provider non configur√©"

```bash
# V√©rifiez le statut de vos providers
python custom_docs/scripts/llm_config.py --status
```

### Erreur : "No module named 'anthropic'"

```bash
# Installez le package requis
pip install anthropic
```

### Erreur : "API key not found"

1. V√©rifiez votre fichier `.env`
2. Assurez-vous que les cl√©s API sont valides
3. Testez avec un autre provider

### Performance lente

1. Utilisez `gemini` (plus rapide que Claude)
2. Essayez le mode `balanced` au lieu de `quality`
3. D√©sactivez `--force_ocr` si pas n√©cessaire

## üìä Comparaison des providers

### Gemini (Google) ‚≠ê Recommand√©
- **Avantages :** Rapide, pr√©-install√©, excellent sur tableaux
- **Inconv√©nients :** Limites de d√©bit API gratuite
- **Meilleur pour :** Usage g√©n√©ral, tableaux, documents multilingues

### Claude (Anthropic)
- **Avantages :** Excellente compr√©hension, bon sur les √©quations
- **Inconv√©nients :** Plus lent, package suppl√©mentaire requis
- **Meilleur pour :** Documents scientifiques, analyses approfondies

### OpenAI
- **Avantages :** Fiable, bonne qualit√© g√©n√©rale
- **Inconv√©nients :** Co√ªt plus √©lev√©, package suppl√©mentaire
- **Meilleur pour :** Usage professionnel, qualit√© constante

### Azure OpenAI
- **Avantages :** Contr√¥le entreprise, conformit√©
- **Inconv√©nients :** Configuration plus complexe
- **Meilleur pour :** Environnements d'entreprise

### Ollama (Local)
- **Avantages :** Gratuit, priv√©, pas de limites API
- **Inconv√©nients :** Installation locale requise, plus lent
- **Meilleur pour :** Documents sensibles, usage hors ligne

## üîç Exemples avanc√©s

### Analyse compl√®te avec fallback
```bash
# Essaie Gemini, puis Claude si √©chec
python custom_docs/scripts/analyze_pdf_deep.py document.pdf --llm --provider gemini || \
python custom_docs/scripts/analyze_pdf_deep.py document.pdf --llm --provider claude
```

### Traitement en lot avec provider optimal
```bash
# Traiter tous les PDFs d'un dossier
for file in inputs/*.pdf; do
    python custom_docs/scripts/convert_to_markdown.py "$file" --mode quality --provider gemini --output outputs/
done
```

### Extraction multi-contenu
```bash
# Extraire tableaux ET √©quations avec le meilleur provider pour chaque
python custom_docs/scripts/extract_specific_content.py document.pdf --content-type tables --llm --provider gemini --output outputs/
python custom_docs/scripts/extract_specific_content.py document.pdf --content-type equations --llm --provider claude --output outputs/
```

---

**üí° Conseil :** Commencez toujours avec `--provider auto` pour laisser le syst√®me choisir le meilleur provider disponible !